--- sstate.bbclass	2024-09-04 13:03:41.981178000 +0300
+++ sstate.bbclass	2024-10-17 15:55:03.316618228 +0300
@@ -4,7 +4,7 @@
 # SPDX-License-Identifier: MIT
 #
 
-SSTATE_VERSION = "14"
+SSTATE_VERSION = "12"
 
 SSTATE_ZSTD_CLEVEL ??= "8"
 
@@ -731,6 +731,7 @@
 
 def pstaging_fetch(sstatefetch, d):
     import bb.fetch2
+    import json
 
     # Only try and fetch if the user has configured a mirror
     mirrors = d.getVar('SSTATE_MIRRORS')
@@ -740,6 +741,17 @@
     # Copy the data object and override DL_DIR and SRC_URI
     localdata = bb.data.createCopy(d)
 
+    #file_mirror_map = json.loads(d.getVar('FILE_MIRROR_MAP')) не действует 
+    
+    with open('./file_mirror_map', 'r') as mapping_file:
+        file_mirror_map = json.load(mapping_file)
+
+    if file_mirror_map:
+        relevant_mirror = file_mirror_map[sstatefetch]
+        if relevant_mirror:
+            mirrors = 'file://.* ' + relevant_mirror
+
+
     dldir = localdata.expand("${SSTATE_DIR}")
     bb.utils.mkdirhier(dldir)
 
@@ -766,7 +778,7 @@
         localdata.setVar('SRC_URI', srcuri)
         try:
             fetcher = bb.fetch2.Fetch([srcuri], localdata, cache=False)
-            fetcher.checkstatus()
+            #fetcher.checkstatus()
             fetcher.download()
 
         except bb.fetch2.BBFetchException:
@@ -950,13 +962,19 @@
 }
 
 BB_HASHCHECK_FUNCTION = "sstate_checkhashes"
+#FILE_MIRROR_MAP = "" не действует
 
 def sstate_checkhashes(sq_data, d, siginfo=False, currentcount=0, summary=True, **kwargs):
     import itertools
+    import requests
+    from ftplib import FTP
+    import json
 
     found = set()
     missed = set()
+    file_mirror_map = {}
 
+    
     def gethash(task):
         return sq_data['unihash'][task]
 
@@ -996,6 +1014,12 @@
     foundLocal = len(found)
     mirrors = d.getVar("SSTATE_MIRRORS")
     if mirrors:
+        mirrors_copy = mirrors[:]
+        mirrors_copy = (mirrors_copy or "").replace('\\n',' ').split()
+        if len(mirrors_copy) % 2 != 0:
+            bb.warn('Invalid mirror data %s, should have paired members.' % data)
+        mirrors_missed = [mirrors_copy[i] for i in range(len(mirrors_copy)) if i % 2]
+
         # Copy the data object and override DL_DIR and SRC_URI
         localdata = bb.data.createCopy(d)
 
@@ -1056,32 +1080,98 @@
         for tid in missed:
             sstatefile = d.expand(getsstatefile(tid, siginfo, d))
             tasklist.append((tid, sstatefile))
+        tasklist_copy = tasklist.copy()
 
+        
         if tasklist:
-            nproc = min(int(d.getVar("BB_NUMBER_THREADS")), len(tasklist))
+            cache_tasks = {}
+            mirrors = (mirrors or "").replace('\\n',' ').split()
+            if len(mirrors) % 2 != 0:
+                bb.warn('Invalid mirror data %s, should have paired members.' % data)
+            mirrors = [mirrors[i] for i in range(len(mirrors)) if i % 2]
+
+            for mirror in mirrors:
+                if 'http' in mirror:
+                    url = 'http://' +  str(str(mirror.split('//')[1]).split('/')[0]) + '/sstate-cache'
+                    response = requests.get(f'{url}/index.txt')
+
+                    # Проверка успешности запроса
+                    if response.status_code == 200:
+                        cache_tasks.update({mirror: response.text.split('\n')})
+                        mirrors_missed.remove(mirror)
+                        
+
+                if 'ftp' in mirror:
+                    try:
+                        ftp = FTP() # Подключение к FTP серверу
+                        ip, port = str(str(mirror.split('//')[1]).split('/')[0]).split(':')
+                        port = int(port)
+                        ftp.connect(ip, port)  
+                        ftp.login()  
+                    
+                        with open('index.txt', 'wb') as local_file:
+                            ftp.retrbinary('RETR /sstate-cache/index.txt', local_file.write)
+
+                        # Закрытие соединения
+                        #ftp.quit()
+
+
+                        with open('index.txt', 'r') as local_file:
+                            content = local_file.read().split('\n')
+                            cache_tasks.update({mirror: content})
+                        mirrors_missed.remove(mirror)
+                    except:
+                        pass
+
+            for arg in tasklist:
+                (tid, sstatefile) = arg
+                srcuri = sstatefile
+                for m, files in cache_tasks.items():
+                    if srcuri in files:
+                        found.add(tid)
+                        missed.remove(tid)
+                        file_mirror_map.update({srcuri: m}) #таким образом будет только одно зеркало, можно сделать чтобы здесь был список из всех зеркал, на которых есть этот файл
+                        tasklist_copy.remove(arg)
+
+            #d.setVar('FILE_MIRROR_MAP', json.dumps(file_mirror_map)) так не работает
+
+            with open('./file_mirror_map', 'w') as mapping_file:
+                json.dump(file_mirror_map, mapping_file, indent=4)
+
+            if mirrors_missed:
+                mirrors_new = ''
+                for i in range(len(mirrors_missed)):
+                    index = mirrors_copy.index(mirrors_missed[i])
+                    mirrors_new += mirrors_copy[index - 1] + ' '
+                    mirrors_new += mirrors_copy[index] + ' '
+
+                localdata.setVar('PREMIRRORS', mirrors_new)
+                nproc = min(int(d.getVar("BB_NUMBER_THREADS")), len(tasklist_copy))
+
+                ## thread-safe counter
+                cnt_tasks_done = itertools.count(start = 1)
+                progress = len(tasklist_copy) >= 100
+                if progress:
+                    msg = "Checking sstate mirror object availability"
+                    bb.event.fire(bb.event.ProcessStarted(msg, len(tasklist_copy)), d)
+
+                # Have to setup the fetcher environment here rather than in each thread as it would race
+                fetcherenv = bb.fetch2.get_fetcher_environment(d)
+                with bb.utils.environment(**fetcherenv):
+                    bb.event.enable_threadlock()
+                    import concurrent.futures
+                    from queue import Queue
+                    connection_cache_pool = Queue(nproc)
+                    checkstatus_init()
+                    with concurrent.futures.ThreadPoolExecutor(max_workers=nproc) as executor:
+                        executor.map(checkstatus, tasklist_copy.copy())
+                    checkstatus_end()
+                    bb.event.disable_threadlock()
 
-            ## thread-safe counter
-            cnt_tasks_done = itertools.count(start = 1)
-            progress = len(tasklist) >= 100
-            if progress:
-                msg = "Checking sstate mirror object availability"
-                bb.event.fire(bb.event.ProcessStarted(msg, len(tasklist)), d)
+                if progress:
+                    bb.event.fire(bb.event.ProcessFinished(msg), d)
 
-            # Have to setup the fetcher environment here rather than in each thread as it would race
-            fetcherenv = bb.fetch2.get_fetcher_environment(d)
-            with bb.utils.environment(**fetcherenv):
-                bb.event.enable_threadlock()
-                import concurrent.futures
-                from queue import Queue
-                connection_cache_pool = Queue(nproc)
-                checkstatus_init()
-                with concurrent.futures.ThreadPoolExecutor(max_workers=nproc) as executor:
-                    executor.map(checkstatus, tasklist.copy())
-                checkstatus_end()
-                bb.event.disable_threadlock()
 
-            if progress:
-                bb.event.fire(bb.event.ProcessFinished(msg), d)
 
     inheritlist = d.getVar("INHERIT")
     if "toaster" in inheritlist:
