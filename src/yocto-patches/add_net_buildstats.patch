--- buildstats.py	(revision e665be2ad94b736d5a07395303fd71937c021ee8)
+++ buildstats.py	(date 1727794002950)
@@ -16,9 +16,10 @@
         bn = d.getVar('BUILDNAME')
         bsdir = os.path.join(d.getVar('BUILDSTATS_BASE'), bn)
         bb.utils.mkdirhier(bsdir)
-        file_handlers =  [('diskstats', self._reduce_diskstats),
-                            ('meminfo', self._reduce_meminfo),
-                            ('stat', self._reduce_stat)]
+        file_handlers = [('diskstats', self._reduce_diskstats),
+                         ('meminfo', self._reduce_meminfo),
+                         ('stat', self._reduce_stat),
+                         ('net/dev', self._reduce_net)]
 
         # Some hosts like openSUSE have readable /proc/pressure files
         # but throw errors when these files are opened. Catch these error
@@ -47,7 +48,10 @@
                 # not strictly necessary, but using it makes the class
                 # more robust should two processes ever write
                 # concurrently.
-                destfile = os.path.join(bsdir, '%sproc_%s.log' % ('reduced_' if handler else '', filename))
+                if filename == 'net/dev':
+                    destfile = os.path.join(bsdir, 'reduced_proc_net.log')
+                else:
+                    destfile = os.path.join(bsdir, '%sproc_%s.log' % ('reduced_' if handler else '', filename))
                 self.proc_files.append((filename, open(destfile, 'ab'), handler))
         self.monitor_disk = open(os.path.join(bsdir, 'monitor_disk.log'), 'ab')
         # Last time that we sampled /proc data resp. recorded disk monitoring data.
@@ -72,6 +76,7 @@
         self.stat_ltimes = None
         # Last time we sampled /proc/pressure. All resources stored in a single dict with the key as filename
         self.last_pressure = {"pressure/cpu": None, "pressure/io": None, "pressure/memory": None}
+        self.net_stats = {}
 
     def close(self):
         self.monitor_disk.close()
@@ -93,6 +98,43 @@
                     b' '.join([values[x] for x in
                                (b'MemTotal', b'MemFree', b'Buffers', b'Cached', b'SwapTotal', b'SwapFree')]) + b'\n')
 
+    def _reduce_net(self, time, data, filename):
+        data = data.split(b'\n')
+        max_receive_diff, max_transmit_diff = 0, 0
+        for line in data[2:]:
+            if b":" not in line:
+                continue
+            parts = line.split()
+            iface = (parts[0].strip(b':')).decode('ascii')
+            receive_bytes = int(parts[1])
+            transmit_bytes = int(parts[9])
+            if iface in self.net_stats:
+                receive_diff = receive_bytes - self.net_stats[iface][-1][0]
+                transmit_diff = transmit_bytes - self.net_stats[iface][-1][1]
+                max_receive_diff, max_transmit_diff = max(receive_diff, max_receive_diff), max(transmit_diff, max_transmit_diff)
+                self.net_stats[iface].append((receive_bytes, transmit_bytes, receive_diff, transmit_diff))
+            else:
+                receive_diff, transmit_diff = 0, 0
+                self.net_stats[iface] = [(receive_bytes, transmit_bytes, receive_diff, transmit_diff)]
+
+        result_parts = []
+        for iface, net_data in self.net_stats.items():
+            result_parts.append(
+                f"{iface}: {net_data[-1][0]} {net_data[-1][1]} {net_data[-1][2]} {net_data[-1][3]}")
+        with open('net_pressure.log', 'w+') as f:
+            with open('current_max_pressure.log', 'w') as f_max:
+                if f_max.tell() != 0:
+                    previous_max_receive_diff, previous_max_transmit_diff = [int(elem) for elem in f_max.readline().split()]
+                    f_max.write(f"{max(max_receive_diff, previous_max_receive_diff)} "
+                                f"{max(max_transmit_diff, previous_max_transmit_diff)}")
+                else:
+                    f_max.write(f"{max_receive_diff} {max_transmit_diff}")
+            f.write(f"{max_receive_diff} {max_transmit_diff}")
+
+        result_str = "\n".join(result_parts) + "\n"
+
+        return time, result_str.encode('ascii')
+
     def _diskstats_is_relevant_line(self, linetokens):
         if len(linetokens) != 14:
             return False
